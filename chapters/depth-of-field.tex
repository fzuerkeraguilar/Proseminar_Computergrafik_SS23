\chapter{Depth-of-Field}
As discussed in chapter \ref{ch:background} virtual cameras are able to take perfect color samples from every angle and thus create an image with infinite \gls{dof}.
However without expensive operations, like the simulation of a lens with path tracing, a virtual camera is only able to create perfect images.
As such the difficulty in simulating depth of field in real-time lies in combining images with infinite \gls{dof} into good approximation of real camera images.
\section{Accumulation buffers}
The image is rendered multiple times.
Each time shifting the virtual camera to simulate the \gls{coc}.
The image around the point on which the camera is pointed moves very little thus creating very little blur.
The image far away from the focus point differ wildly and therefore are very blurred.
Rendering workload is proportional to area of biggest \gls{coc}. 
Converges to correct answer
\cite{Haeberli.1990}

\section{Single-Layer approaches}

\subsection{Scattering methods}
For each pixel in image a \gls{coc} is calculated based upon the z-buffer.
The pixels color is then used by a circular sprite with size of \gls{coc} and transparency proportional to size of \gls{coc}.
Final pixel color is based on sum of all sprites overlapping it.
Requires a sorting of every pixel based on depth and is often not practical for real-time applications.
\cite{Potmesil.1981}
Improvements by \cite{Rokita.1993} and \cite{Dudkiewicz.1995}
\subsection{Gathering methods}
z-buffer is generated with image.

Each pixel is blurred according to distance from focus plane.
Can be implemented by LERPing between mip-maps of image.
\cite{Gilham.2007} and \cite{Hammon.2008}
or \cite{Lee.2009}

\section{Multi-Layer approaches}

\cite{Kraus.2007}
\cite{Zhou.2007}
